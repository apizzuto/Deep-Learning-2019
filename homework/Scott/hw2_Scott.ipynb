{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAT 479: Deep Learning (Spring 2019)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
    "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat479-ss2019/  \n",
    "GitHub repository: https://github.com/rasbt/stat479-deep-learning-ss19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p matplotlib,torch,pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2: Implementing a Neuron with Nonlinear Activation (40 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The homework assignment is due on Thu, Feb 21, 2019 (11:59 pm) and should be submitted via Canvas.**\n",
    "\n",
    "- Please submit the `.ipynb` file with your solution as well as an HTML version (use `File -> export as -> HTML`) as a backup in case we cannot open your .ipynb on our computer.\n",
    "\n",
    "- I recommend using the conda package manager for installing Python 3.7 and Jupyter Notebook (or Jupyter Lab). You may find the lecture notes from my previous machine learning class (https://github.com/rasbt/stat479-machine-learning-fs18/blob/master/03_python/03_python_notes.pdf, Section 3) helpful. \n",
    "\n",
    "- Also consider this YouTube tutorial for a more visual setup guide for conda: https://www.youtube.com/watch?v=YJC6ldI3hWk (Python Tutorial: Anaconda - Installation and Using Conda). Please reach out to me or the TA if you need any help of have questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a neuron model similar to ADALINE (discussed in class) but the activation function (which is an identity function in ADALINE) is replaced by a non-linear activation function. \n",
    "\n",
    "![](../images/neuron.png)\n",
    "\n",
    "\n",
    "This activation function is defined as\n",
    "\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}},\n",
    "$$\n",
    "\n",
    "where z denotes the net input,  $z = \\mathbf{w}^\\top \\mathbf{x}$ (for a single training example, we write $z^{[i]} = \\mathbf{w}^\\top \\mathbf{x}^{[i]}$).\n",
    "\n",
    "Assume now that we want learn the parameters of the neuron model for a binary classification task with class labels $y \\in \\{0, 1\\}$ similar to ADALINE. We use the same loss function, mean squared error (MSE), as in ADALINE, during training:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\mathbf{\\hat{y}}, \\mathbf{y}) = \\frac{1}{n} \\sum_{i}^{} (\\hat{y}^{[i]} - y^{[i]})^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: Compute the Loss Gradients with respect to the weights and bias unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to derive the gradient of the loss $\\mathcal{L}$ with respect to the weight vector and the bias unit and formulate the learning rule. \n",
    "\n",
    "Remember that the gradient of the loss is defined as \n",
    "\n",
    "$$\n",
    "\\nabla_\\mathbf{w} \\mathcal{L}(\\mathbf{w}) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial \\mathcal{L}(\\mathbf{w})}{\\partial w_1}\\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial \\mathcal{L}(\\mathbf{w})}{\\partial w_m}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**For simplicity, it is sufficient if you write down the partial derivative and learning rule for a single weight $w_j$ and the bias unit $b$**. \n",
    "\n",
    "To provide you with a hint, recall that we computed the partial Loss derivatives for ADALINE as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_j} &= \\frac{\\partial}{\\partial w_j} \\frac{1}{n} \\sum_i (\\hat{y}^{[i]} - y^{[i]} )^2\\\\\n",
    "&= \\frac{\\partial}{\\partial w_j}  \\frac{1}{n} \\sum_i (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]})^2\\\\\n",
    "\\\\\n",
    "&= \\quad ... \\\\\n",
    "\\\\\n",
    "&= \\sum_i \\frac{2}{n}  (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]})   x_j^{[i]}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b} &= \\frac{\\partial}{\\partial b} \\frac{1}{n}\\sum_i (\\hat{y}^{[i]} - y^{[i]} )^2\\\\\n",
    "&= \\frac{\\partial}{\\partial b}  \\frac{1}{n} \\sum_i (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]})^2\\\\\n",
    "\\\\\n",
    "&= \\quad ... \\\\\n",
    "\\\\\n",
    "&= \\sum_i \\frac{2}{n}  (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]})\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, your task is to derive $\\frac{\\partial \\mathcal{L}}{\\partial w_j}$ and $\\frac{\\partial \\mathcal{L}}{\\partial b}$ for the neuron model with the non-linear activation function $\\sigma(\\mathbf{w}^\\top \\mathbf{x}) =  1 / (1+exp(-\\mathbf{w}^\\top \\mathbf{x}))$.\n",
    "\n",
    "For partial credits in case of a wrong solution, also write down the individual steps in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!!!Fill in with your solution below!!!**\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_j} &= \\frac{\\partial}{\\partial w_j} \\frac{1}{n}\\sum_i (\\hat{y}^{[i]} - y^{[i]} )^2\\\\\n",
    "&= \\frac{\\partial}{\\partial w_j} \\frac{1}{n}\\sum_i (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]} )^2\\\\\n",
    "&= \\frac{2}{n}\\sum_i (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]} ) \\frac{\\partial}{\\partial w_j} \\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) \\\\\n",
    "&= \\frac{2}{n}\\sum_i \\left(\\frac{1}{1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)} - y^{[i]} \\right) \\frac{\\partial}{\\partial w_j} \\frac{1}{1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)} \\\\\n",
    "&= \\frac{2}{n}\\sum_i \\left(\\frac{1}{1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)} - y^{[i]} \\right) \\frac{x_j^{[i]} \\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)}{\\left(1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)\\right)^2} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**!!!Fill in with your solution below!!!**\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial b} &= \\frac{\\partial}{\\partial b} \\frac{1}{n} \\sum_i (\\hat{y}^{[i]} - y^{[i]} )^2\\\\\n",
    "&= \\frac{\\partial}{\\partial b} \\frac{1}{n}\\sum_i (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]} )^2\\\\\n",
    "&= \\frac{2}{n}\\sum_i (\\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) - y^{[i]} ) \\frac{\\partial}{\\partial b} \\sigma(\\mathbf{w}^T\\mathbf{x}^{[i]} + b) \\\\\n",
    "&= \\frac{2}{n}\\sum_i \\left(\\frac{1}{1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)} - y^{[i]} \\right) \\frac{\\partial}{\\partial b} \\frac{1}{1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)} \\\\\n",
    "&= \\frac{2}{n}\\sum_i \\left(\\frac{1}{1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)} - y^{[i]} \\right) \\frac{\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)}{\\left(1+\\exp(-\\mathbf{w}^T\\mathbf{x}^{[i]} - b)\\right)^2} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the code below, the missing parts are indicated via \n",
    "\n",
    "    # <YOUR CODE HERE>\n",
    "    \n",
    "to implement the neuron model (it is very similar to the ADALINE model we discussed in class, except the derivatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports (Just Execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No modification required.** You should execute this code and are encouraged to explore it further, but it is recommended to  not make any alterations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset (Just Execute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No modification required.** You should execute this code and are encouraged to explore it further, but it is recommended to  not make any alterations here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1   x2   x3   x4  y\n",
       "145  6.7  3.0  5.2  2.3  1\n",
       "146  6.3  2.5  5.0  1.9  1\n",
       "147  6.5  3.0  5.2  2.0  1\n",
       "148  6.2  3.4  5.4  2.3  1\n",
       "149  5.9  3.0  5.1  1.8  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../hw2_dataset_iris.data', index_col=None, header=None)\n",
    "df.columns = ['x1', 'x2', 'x3', 'x4', 'y']\n",
    "df = df.iloc[50:150]\n",
    "df['y'] = df['y'].apply(lambda x: 0 if x == 'Iris-versicolor' else 1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and target\n",
    "\n",
    "X = torch.tensor(df[['x2', 'x3']].values, dtype=torch.float)\n",
    "y = torch.tensor(df['y'].values, dtype=torch.int)\n",
    "\n",
    "# Shuffling & train/test split\n",
    "\n",
    "torch.manual_seed(123)\n",
    "shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "\n",
    "X, y = X[shuffle_idx], y[shuffle_idx]\n",
    "\n",
    "percent70 = int(shuffle_idx.size(0)*0.7)\n",
    "\n",
    "X_train, X_test = X[shuffle_idx[:percent70]], X[shuffle_idx[percent70:]]\n",
    "y_train, y_test = y[shuffle_idx[:percent70]], y[shuffle_idx[percent70:]]\n",
    "\n",
    "# Normalize (mean zero, unit variance)\n",
    "\n",
    "mu, sigma = X_train.mean(dim=0), X_train.std(dim=0)\n",
    "X_train = (X_train - mu) / sigma\n",
    "X_test = (X_test - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121447668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], label='class 0')\n",
    "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], label='class 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAEo9JREFUeJzt3X+MXWWdx/HP13FMJwHbQCexzJ1uqzUFnB8QrrTYqAmY8CN2izU0goF0V+3GrBZ/bAmkBLq1UUwNJARNQ4MxxC5miDhCcJ1V64ZsFHRq3bZj0y2Q1N6BxDqkQNIhDMN3/7i3v6edmXPOvec5z3m/EjLc08tzvueGfnr6PN/zXHN3AQDi8Z68CwAAZItgB4DIEOwAEBmCHQAiQ7ADQGQIdgCIDMEOAJEh2AEgMgQ7AETmvXmcdP78+b5o0aI8Tg0AhbVr166/u3vndO/LJdgXLVqk4eHhPE4NAIVlZodm8j6mYgAgMgQ7AESGYAeAyOQyxz6ViYkJ1Wo1vfXWW3mXEow5c+aoUqmovb0971IAFEgwwV6r1XThhRdq0aJFMrO8y8mdu2tsbEy1Wk2LFy/OuxwABRLMVMxbb72liy++mFBvMDNdfPHF/A0GwKwFE+ySCPUz8HkASCKoYAeA6OwZkB7qkTbNq//cM9D0UxLs09i0aZO+973vNWXsXbt2qbe3V0uWLNH69evF988CkdkzID2zXnr9sCSv/3xmfdPDnWDP0Ze//GVt375dBw8e1MGDB/XLX/4y75IAZOk3m6WJ8dOPTYzXjzdRYYN9cPeoVjywU4vvflYrHtipwd2jqcd8/PHH1dfXp/7+ft1+++1n/fr27dv10Y9+VP39/frsZz+rY8eOSZKefPJJ9fT0qL+/X5/4xCckSSMjI7r66qt1xRVXqK+vTwcPHjxtrFdffVVvvPGGli9fLjPTHXfcocHBwdTXACAgr9dmdzwjwbQ7zsbg7lHd89RejU9MSpJGj47rnqf2SpJuvrIr0ZgjIyPasmWLfve732n+/Pl67bXXznrP6tWr9aUvfUmSdO+99+qxxx7TV7/6VW3evFlDQ0Pq6urS0aNHJUnbtm3TnXfeqc9//vN6++23NTk5edpYo6OjqlQqJ15XKhWNjqb/wwlAQOZWGtMwUxxvokLesW8dOnAi1I8bn5jU1qEDicfcuXOnbrnlFs2fP1+SdNFFF531nn379unjH/+4ent7tWPHDo2MjEiSVqxYobVr12r79u0nAvyaa67Rt7/9bX33u9/VoUOH1NHRkbg2pJDDwhVwwnX3Se1n/N5v76gfb6JCBvsrR8dndTwra9eu1SOPPKK9e/fq/vvvP9Fjvm3bNm3ZskWHDx/WVVddpbGxMd122216+umn1dHRoZtuukk7d+48bayuri7Vaif/Olar1dTVlexvGziHnBaugBP61kgrH5bmdkuy+s+VD9ePN1Ehg/2SeVPf/Z7r+Exce+21evLJJzU2NiZJU07FvPnmm1qwYIEmJia0Y8eOE8dfeuklLVu2TJs3b1ZnZ6cOHz6sl19+WR/84Ae1fv16rVq1Snv27DltrAULFuj973+/nn/+ebm7Hn/8ca1atSpx/ZhCTgtXwGn61khf3ydtOlr/2eRQlwoa7BuuX6qO9rbTjnW0t2nD9UsTj/mRj3xEGzdu1Cc/+Un19/frG9/4xlnv+da3vqVly5ZpxYoVuvTSS0/Ws2GDent71dPTo4997GPq7+/XwMCAenp6dMUVV2jfvn264447zhrvBz/4gb74xS9qyZIl+tCHPqQbb7wxcf2YQk4LV0DeLI/e6Wq16md+0cb+/ft12WWXzXiMwd2j2jp0QK8cHdcl8zq04fqliRdOQzbbzwWneKjnHAtX3fU7J6BgzGyXu1ene18hu2KkevdLjEGODF13X31O/dTpmBYsXAF5Sz0VY2bdZvZbM/uLmY2Y2Z1ZFAakltPCFZC3LO7Y35H0TXf/k5ldKGmXmf3K3f+SwdhAOn1rCHKUTuo7dnd/1d3/1Pj3NyXtl8QcCQDkJNOuGDNbJOlKSS9kOS4AYOYyC3Yzu0DSTyV9zd3fmOLX15nZsJkNHzlyJKvTAgDOkEmwm1m76qG+w92fmuo97v6ou1fdvdrZ2ZnFaVuimdv2bty4Ud3d3brggguaMj6AcsqiK8YkPSZpv7s/mL6k8li5cqX+8Ic/5F0GgMhkcce+QtLtkq41sz83/rkpg3HPrwmbO7Vy215JWr58uRYsWJC6bgA4Vep2R3f/H0mt/XLO45s7HX/w5PjmTlLi1rZWb9sLAM1SyL1imrG5E9v2AohFMYM9p82dsty2FwCapZjBfq5vH0nxrSSt3rYXAJqlmMHehG8lyWPb3rvuukuVSkXHjh1TpVLRpk2bEtcPAMcVdtte7Rmoz6m/XqvfqV93X5R7grBtL4Djot+2l82dAGBqxZyKAQCcU1DBnse0UMj4PAAkEUywz5kzR2NjY4RZg7trbGxMc+bMybsUAAUTzBx7pVJRrVYTOz+eNGfOHFUqyVs4AZRTMMHe3t6uxYsX510GABReMFMxAIBsEOwAEBmCHQAiQ7AjnSbsiw8gnWAWT1FATdgXH0B63LEjuSbsiw8gPYIdyeW0Lz6A8yPYkVwT9sUHkB7BjuSasC8+gPQIdiTXt0Za+bA0t1uS1X+ufJiF0zzRpQTRFYO02Bc/HHQpoYE7diAWdCmhgWAHYkGXEhoIdiAWdCmhgWAHYkGXEhoIdsQt9C6RLOujSwkNdMUgXqF3iTSjPrqUIO7YEbPQu0RCrw+FRbAjXqF3iYReHwqLYEe8Qu8SCb0+FBbBjnhdd5/O/l/8PeF0idDFgiYh2BGvvz4v6d0zDr7bOB4AuljQJObuLT9ptVr14eHhlp8XJfPvF0k+efZxa5Puf6319QApmdkud69O9z7u2BGvqUL9fMeBSBDsiJe1ze44EIlMgt3MfmhmfzOzfVmMB2TiqrWzOw5EIqs79h9JuiGjsYBsfPpBqfqFk3fo1lZ//ekH860LaLJMthRw9+fMbFEWYwGZ+vSDBDlKhzl2AIhMy4LdzNaZ2bCZDR85cqRVpwWA0mlZsLv7o+5edfdqZ2dnq04LAKXDVAwARCardscnJP1e0lIzq5nZF7IYFwAwe1l1xdyaxTgAgPSYigGAyBDsABAZgh0AIkOwA0BkCHYAiAzBDgCRIdgBIDIEOwBEhmAHgMgQ7AAQGYIdACJDsANAZAh2AIgMwQ4AkSHYASAyBDsARIZgB4DIEOwAEBmCHQAiQ7ADQGQIdgCIDMGOuO0ZkB7qkTbNq//cM5B3RUDTvTfvAoCm2TMgPbNemhivv379cP21JPWtya8uoMm4Y0e8frP5ZKgfNzFePw5EjGBHvF6vze44EAmCHfGaW5ndcSASBDvidd19UnvH6cfaO+rHgYgR7Egn5K6TvjVS/22StdVfW1v9dZqF06yvN+TPD4VFVwySC73rZM+A9L//Iflk/bVP1l8vXJ6svqyvN/TPD4XFHTuSC73rJOv6Qh8PaCDYkVzoXSdZ1xf6eEADwY7kQu86ybq+0McDGgj2LJVtISz0rpOs6wt9PKCBYM/K8YWw1w9L8pMLYTGHe98aaeXD0txuSVb/ufLhcBb+sq4v9PGABnP3lp+0Wq368PBwy8/bVA/1NEL9DHO7pa/va309AKJjZrvcvTrd+7hjzwoLYQACkUmwm9kNZnbAzF40s7uzGLNwWAgDEIjUwW5mbZK+L+lGSZdLutXMLk87buGwEAYgEFncsV8t6UV3f9nd35b0E0mrMhi3WIqwEFa2rh2pnNeM0stiS4EuSaeuGtYkLctg3OLpWxNWkJ+qjI+vl/GaAbVw8dTM1pnZsJkNHzlypFWnxXFlfHy9jNcMKJtgH5XUfcrrSuPYadz9UXevunu1s7Mzg9NiVsrYtVPGawaUTbD/UdKHzWyxmb1P0uckPZ3BuMhSGbt2ynjNgDIIdnd/R9JXJA1J2i9pwN1H0o6LjJWxa6eM1wwoo/3Y3f0Xkn6RxVhokuOLhb/ZXJ+KmFupB1zKRcTB3aPaOnRArxwd1yXzOrTh+qW6+cquDArOQJOuGQgdWwogscHdo7rnqb0an5g8cayjvU3fWd0bTrgDEWFLATTd1qEDp4W6JI1PTGrr0IGcKgIgEexI4ZWj47M6DqA1CHYkdsm8jlkdB9AaBDsS23D9UnW0t512rKO9TRuuX5pTRQCkjLpiUE7HF0iz7IoJussGKAiCHancfGVXZsF7ZpfN6NFx3fPU3hPnATAzTMUgGHTZANkg2BEMumyAbBDsCAZdNkA2CHYEoxldNoO7R7XigZ1afPezWvHATg3uPmvjUSA6LJ4iGFl32bAYi7Ii2BGULLtszrcYS7AjZkzFIFosxqKsCHZEi8VYlBXBjmix5QHKijl2RKsZWx4ARUCwI2pZLsYCRcFUDABEhmAHgMgQ7AAQGYIdACLD4ikwC3wRCIqAYAdmiL1nUBRMxQAzxBeBoCgIdmCG2HsGRUGwAzPE3jMoCoIdmCH2nkFRsHgKzBB7z6AoCHZgFth7BkXAVAwARIZgB4DIEOwAEBnm2EukjI/Dl/GaAYK9JMr4OHwZrxmQmIopjTI+Dl/GawaklMFuZreY2YiZvWtm1ayKQvbK+Dh8Ga8ZkNLfse+TtFrScxnUgiYq4+PwZbxmQEoZ7O6+3935e20BlPFx+DJeMyCxeFoaZXwcvozXDEiSufv532D2a0kfmOKXNrr7zxvv+W9J/+buw+cZZ52kdZK0cOHCqw4dOpS0ZgAoJTPb5e7TrmdOe8fu7p/KoiB3f1TSo5JUrVbP/6cJACAx2h0BIDJp2x0/Y2Y1SddIetbMhrIpCwCQVKrFU3f/maSfZVQLACADdMUgFfZiAcJDsCMx9mIBwsTiKRJjLxYgTAQ7EmMvFiBMBDsSYy8WIEwEOxJjLxYgTCyeZij0DpF7B/fqiRcOa9JdbWa6dVm3ttzcm3g89mIBwkSwZyT0DpF7B/fqx8//9cTrSfcTr9OGewjXB+AkpmIyEnqHyBMvHJ7VcQDFRbBnJPQOkclz7OJ5ruMAiotgz0joHSJtZrM6DqC4CPaMhN4hcuuy7lkdB1BcpV48zbKLJfQOkeMLpFl2xQAI07TfoNQM1WrVh4fP+WVLLXFmF4tUv8P+zureYMIYAE41029QKu1UTOhdLACQVGmDPfQuFgBIqrTBHnoXCwAkVdpgD72LBQCSKm1XTOhdLACQVGmDXWKfEwBxKu1UDADEimAHgMgQ7AAQmVLPsSM8oX9ZCVAEBDuCEfqXlQBFwVQMgsE2D0A2CHYEg20egGwQ7AgG2zwA2SDYEQy2eQCyweJpwMrWIcI2D0A2CPZAlbVDhG0egPSYigkUHSIAkiLYA0WHCICkCPZA0SECICmCPVB0iABIisXTQNEhAiCpVMFuZlslrZT0tqSXJP2Tux/NojDQIQIgmbRTMb+S1OPufZL+T9I96UsCAKSRKtjd/b/c/Z3Gy+clVdKXBABII8vF03+W9J8ZjgcASGDaOXYz+7WkD0zxSxvd/eeN92yU9I6kHecZZ52kdZK0cOHCRMWW7RF7AEjC3D3dAGZrJf2LpOvc/dhM/ptqterDw8OzOs+Zj9hL9fa/76zuJdwBlIKZ7XL36nTvSzUVY2Y3SLpL0j/ONNST4hF7AJiZtHPsj0i6UNKvzOzPZrYtg5qmxCP2ADAzqfrY3X1JVoVM55J5HRqdIsR5xB4ATleYLQV4xB4AZqYwWwrwiD0AzExhgl3iEXsAmInCTMUAAGaGYAeAyBDsABAZgh0AIkOwA0BkCHYAiEzqTcASndTsiKRDLT9xPuZL+nveRQSIz2VqfC7nxmcj/YO7d073plyCvUzMbHgmu7GVDZ/L1Phczo3PZuaYigGAyBDsABAZgr35Hs27gEDxuUyNz+Xc+GxmiDl2AIgMd+wAEBmCvQXM7BYzGzGzd82s9Kv6ZnaDmR0wsxfN7O686wmBmf3QzP5mZvvyriUkZtZtZr81s780fg/dmXdNRUCwt8Y+SaslPZd3IXkzszZJ35d0o6TLJd1qZpfnW1UQfiTphryLCNA7kr7p7pdLWi7pX/n/ZXoEewu4+35351u3666W9KK7v+zub0v6iaRVOdeUO3d/TtJredcRGnd/1d3/1Pj3NyXtl8SXMkyDYEerdUk6fMrrmviNihkws0WSrpT0Qr6VhK9Q36AUMjP7taQPTPFLG939562uB4iJmV0g6aeSvubub+RdT+gI9oy4+6fyrqEgRiV1n/K60jgGTMnM2lUP9R3u/lTe9RQBUzFotT9K+rCZLTaz90n6nKSnc64JgTIzk/SYpP3u/mDe9RQFwd4CZvYZM6tJukbSs2Y2lHdNeXH3dyR9RdKQ6gthA+4+km9V+TOzJyT9XtJSM6uZ2RfyrikQKyTdLulaM/tz45+b8i4qdDx5CgCR4Y4dACJDsANAZAh2AIgMwQ4AkSHYASAyBDsARIZgB4DIEOwAEJn/B4jm9qeNNvBNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123568908>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], label='class 0')\n",
    "plt.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], label='class 1')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2: Implement the Neuron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to complete the `backward` method to compute the gradients based on the gradients you computed in TASK1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronModel():\n",
    "    def __init__(self, num_features):\n",
    "        self.num_features = num_features\n",
    "        self.weights = torch.zeros(num_features, 1, \n",
    "                                   dtype=torch.float)\n",
    "        self.bias = torch.zeros(1, dtype=torch.float)\n",
    "        \n",
    "    def activation_func(self, x):\n",
    "        return 1. / (1. + torch.exp(-x))\n",
    "    \n",
    "    def netinput_func(self, x, w, b):\n",
    "         return torch.add(torch.mm(x, w), b)\n",
    "\n",
    "    def forward(self, x):\n",
    "        netinputs = self.netinput_func(x, self.weights, self.bias)\n",
    "        activations = self.activation_func(netinputs)\n",
    "        return activations.view(-1)\n",
    "        \n",
    "    def backward(self, x, yhat, y):  \n",
    "        \n",
    "        # note that here, \"yhat\" are the \"activations\" \n",
    "        netinputs = self.netinput_func(x, self.weights, self.bias)\n",
    "        \n",
    "        ###############################################################################\n",
    "        # YOU ONLY NEED TO EDIT IN THE BOX BELOW\n",
    "        ###############################################################################\n",
    "        print(x.t())\n",
    "        \n",
    "        grad_loss_yhat = 2.*(y - yhat)\n",
    "        grad_yhat_bias = torch.exp(-netinputs)*self.activation_func(netinputs)**2\n",
    "        grad_yhat_weights = torch.mm(x.t(),torch.exp(-netinputs))*self.activation_func(netinputs)**2\n",
    "        \n",
    "        grad_loss_weights = grad_loss_yhat*grad_yhat_weights/y.size(0)\n",
    "        \n",
    "        grad_loss_bias = grad_loss_yhat*grad_yhat_bias/y.size(0)\n",
    "        ################################################################################\n",
    "        \n",
    "        return (-1)*grad_loss_weights, (-1)*grad_loss_bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No modifications required beyond this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You do not need to modify anything below. However, you should run and analyze the code to verify that your implementation of the Neuron model is likely correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Neuron Model (Just Execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "##### Training and evaluation wrappers\n",
    "###################################################\n",
    "\n",
    "def loss(yhat, y):\n",
    "    return torch.mean((yhat - y)**2) / y.size(0)\n",
    "\n",
    "\n",
    "def train(model, x, y, num_epochs,\n",
    "          learning_rate=0.01, seed=123, minibatch_size=10):\n",
    "    cost = []\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        #### Shuffle epoch\n",
    "        shuffle_idx = torch.randperm(y.size(0), dtype=torch.long)\n",
    "        minibatches = torch.split(shuffle_idx, minibatch_size)\n",
    "        \n",
    "        for minibatch_idx in minibatches:\n",
    "\n",
    "            #### Compute outputs ####\n",
    "            yhat = model.forward(x[minibatch_idx])\n",
    "\n",
    "            #### Compute gradients ####\n",
    "            negative_grad_w, negative_grad_b = \\\n",
    "                model.backward(x[minibatch_idx], yhat, y[minibatch_idx])\n",
    "\n",
    "            #### Update weights ####\n",
    "            model.weights += learning_rate * negative_grad_w\n",
    "            model.bias += learning_rate * negative_grad_b\n",
    "            \n",
    "            #### Logging ####\n",
    "            #minibatch_loss = loss(yhat, y[minibatch_idx])\n",
    "            #print('    Minibatch MSE: %.3f' % minibatch_loss)\n",
    "\n",
    "        #### Logging ####\n",
    "        yhat = model.forward(x)\n",
    "        curr_loss = loss(yhat, y)\n",
    "        print('Epoch: %03d' % (e+1), end=\"\")\n",
    "        print(' | MSE: %.5f' % curr_loss)\n",
    "        cost.append(curr_loss)\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6795,  0.1064, -2.4725, -0.1801, -1.0398,  2.1123, -0.1801,  2.6854,\n",
      "          1.5392,  0.1064],\n",
      "        [-0.0292, -0.7966, -1.8198, -0.1571, -0.5408,  1.5055,  2.2729,  1.8892,\n",
      "         -0.5408, -0.5408]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-74749c2bdac3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m              \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m              \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m              minibatch_size=10)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-6234a6c14369>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, x, y, num_epochs, learning_rate, seed, minibatch_size)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#### Compute gradients ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mnegative_grad_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_grad_b\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mminibatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mminibatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m#### Update weights ####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-a3eb9b057baa>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, x, yhat, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mgrad_loss_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mgrad_yhat_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnetinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mgrad_yhat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnetinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetinputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mgrad_loss_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_loss_yhat\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_yhat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "model = NeuronModel(num_features=X_train.size(1))\n",
    "cost = train(model, \n",
    "             X_train, y_train.float(),\n",
    "             num_epochs=150,\n",
    "             learning_rate=0.5,\n",
    "             seed=123,\n",
    "             minibatch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Trained Model  (Just Execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(cost)), cost)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weights', model.weights)\n",
    "print('Bias', model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_where(cond, x_1, x_2):\n",
    "    return (cond * x_1) + ((1-cond) * x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.forward(X_train)\n",
    "train_acc = torch.mean(\n",
    "    (custom_where(train_pred > 0.5, 1, 0).int() == y_train).float())\n",
    "\n",
    "test_pred = model.forward(X_test)\n",
    "test_acc = torch.mean(\n",
    "    (custom_where(test_pred > 0.5, 1, 0).int() == y_test).float())\n",
    "\n",
    "print('Training Accuracy: %.2f' % (train_acc*100))\n",
    "print('Test Accuracy: %.2f' % (test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary  (Just Execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### 2D Decision Boundary\n",
    "##########################\n",
    "\n",
    "w, b = model.weights, model.bias\n",
    "\n",
    "x_min = -3\n",
    "y_min = ( (-(w[0] * x_min) - b[0]) \n",
    "          / w[1] )\n",
    "\n",
    "x_max = 3\n",
    "y_max = ( (-(w[0] * x_max) - b[0]) \n",
    "          / w[1] )\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, figsize=(7, 3))\n",
    "\n",
    "ax[0].plot([x_min, x_max], [y_min, y_max])\n",
    "ax[1].plot([x_min, x_max], [y_min, y_max])\n",
    "\n",
    "ax[0].scatter(X_train[y_train==0, 0], X_train[y_train==0, 1], label='class 0', marker='o')\n",
    "ax[0].scatter(X_train[y_train==1, 0], X_train[y_train==1, 1], label='class 1', marker='s')\n",
    "\n",
    "ax[1].scatter(X_test[y_test==0, 0], X_test[y_test==0, 1], label='class 0', marker='o')\n",
    "ax[1].scatter(X_test[y_test==1, 0], X_test[y_test==1, 1], label='class 1', marker='s')\n",
    "\n",
    "ax[1].legend(loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
